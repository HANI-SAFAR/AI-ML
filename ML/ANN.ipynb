{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kklCXxdXYR-C"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "NF_IbXwmYUiW",
        "outputId": "bbb1e681-396d-4f58-a1af-fe7f132762d9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc2a9d9b-1546-4891-9ab9-89962e5fd071\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc2a9d9b-1546-4891-9ab9-89962e5fd071\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving heart_failure_clinical_records_dataset.csv to heart_failure_clinical_records_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "zVIQ7Gp-iuWq",
        "outputId": "9590ef2e-ca1f-481a-95be-564cedc0ac76"
      },
      "source": [
        "#loading data\n",
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0  75.0        0                       582  ...        0     4            1\n",
              "1  55.0        0                      7861  ...        0     6            1\n",
              "2  65.0        0                       146  ...        1     7            1\n",
              "3  50.0        1                       111  ...        0     7            1\n",
              "4  65.0        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNNtaZOPi17A",
        "outputId": "b2959303-3b01-4724-ac84-cc1e13f24c77"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 299 entries, 0 to 298\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   age                       299 non-null    float64\n",
            " 1   anaemia                   299 non-null    int64  \n",
            " 2   creatinine_phosphokinase  299 non-null    int64  \n",
            " 3   diabetes                  299 non-null    int64  \n",
            " 4   ejection_fraction         299 non-null    int64  \n",
            " 5   high_blood_pressure       299 non-null    int64  \n",
            " 6   platelets                 299 non-null    float64\n",
            " 7   serum_creatinine          299 non-null    float64\n",
            " 8   serum_sodium              299 non-null    int64  \n",
            " 9   sex                       299 non-null    int64  \n",
            " 10  smoking                   299 non-null    int64  \n",
            " 11  time                      299 non-null    int64  \n",
            " 12  DEATH_EVENT               299 non-null    int64  \n",
            "dtypes: float64(3), int64(10)\n",
            "memory usage: 30.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "6QLVpfTfi9M2",
        "outputId": "4f1a2de2-5362-48f0-978b-599e5707c6d5"
      },
      "source": [
        "cols= [\"#6daa9f\",\"#774571\"]\n",
        "sns.countplot(x= data[\"DEATH_EVENT\"], palette= cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea112a0ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twf1MxTqjCO5"
      },
      "source": [
        "#assigning values to features as X and target as y\n",
        "X=data.drop([\"DEATH_EVENT\"],axis=1)\n",
        "y=data[\"DEATH_EVENT\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "S_99Tt5NjZG9",
        "outputId": "4046b502-881c-43a8-c064-74b1c854c646"
      },
      "source": [
        "#Set up a standard scaler for the features\n",
        "col_names = list(X.columns)\n",
        "s_scaler = preprocessing.StandardScaler()\n",
        "X_df= s_scaler.fit_transform(X)\n",
        "X_df = pd.DataFrame(X_df, columns=col_names)   \n",
        "X_df.describe().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>299.0</td>\n",
              "      <td>5.265205e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-1.754448</td>\n",
              "      <td>-0.828124</td>\n",
              "      <td>-0.070223</td>\n",
              "      <td>0.771889</td>\n",
              "      <td>2.877170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anaemia</th>\n",
              "      <td>299.0</td>\n",
              "      <td>3.594301e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>1.147968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <td>299.0</td>\n",
              "      <td>3.713120e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.576918</td>\n",
              "      <td>-0.480393</td>\n",
              "      <td>-0.342574</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>7.514640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diabetes</th>\n",
              "      <td>299.0</td>\n",
              "      <td>1.113936e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>1.179830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ejection_fraction</th>\n",
              "      <td>299.0</td>\n",
              "      <td>3.341808e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-2.038387</td>\n",
              "      <td>-0.684180</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>0.585389</td>\n",
              "      <td>3.547716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-4.841909e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>1.359272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelets</th>\n",
              "      <td>299.0</td>\n",
              "      <td>1.009969e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-2.440155</td>\n",
              "      <td>-0.520870</td>\n",
              "      <td>-0.013908</td>\n",
              "      <td>0.411120</td>\n",
              "      <td>6.008180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serum_creatinine</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-2.227872e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.865509</td>\n",
              "      <td>-0.478205</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>0.005926</td>\n",
              "      <td>7.752020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serum_sodium</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-8.627435e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-5.363206</td>\n",
              "      <td>-0.595996</td>\n",
              "      <td>0.085034</td>\n",
              "      <td>0.766064</td>\n",
              "      <td>2.582144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-5.940993e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>0.735688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoking</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-3.861645e-17</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.454161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-1.069379e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-1.629502</td>\n",
              "      <td>-0.739000</td>\n",
              "      <td>-0.196954</td>\n",
              "      <td>0.938759</td>\n",
              "      <td>1.997038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          count          mean  ...       75%       max\n",
              "age                       299.0  5.265205e-16  ...  0.771889  2.877170\n",
              "anaemia                   299.0  3.594301e-16  ...  1.147968  1.147968\n",
              "creatinine_phosphokinase  299.0  3.713120e-18  ...  0.000166  7.514640\n",
              "diabetes                  299.0  1.113936e-16  ...  1.179830  1.179830\n",
              "ejection_fraction         299.0  3.341808e-18  ...  0.585389  3.547716\n",
              "high_blood_pressure       299.0 -4.841909e-16  ...  1.359272  1.359272\n",
              "platelets                 299.0  1.009969e-16  ...  0.411120  6.008180\n",
              "serum_creatinine          299.0 -2.227872e-18  ...  0.005926  7.752020\n",
              "serum_sodium              299.0 -8.627435e-16  ...  0.766064  2.582144\n",
              "sex                       299.0 -5.940993e-18  ...  0.735688  0.735688\n",
              "smoking                   299.0 -3.861645e-17  ...  1.454161  1.454161\n",
              "time                      299.0 -1.069379e-16  ...  0.938759  1.997038\n",
              "\n",
              "[12 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkd5VpVOjisH"
      },
      "source": [
        "#spliting test and training sets\n",
        "X_train, X_test, y_train,y_test = train_test_split(X_df,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "2aiq25WpkIIC",
        "outputId": "c25e1d3d-34bd-4d61-d528-693e82483c8b"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>-0.238646</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>-1.107370</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>2.464570e+00</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>0.964571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.771889</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.434454</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-1.107370</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.982581e-01</td>\n",
              "      <td>-0.187726</td>\n",
              "      <td>1.220084</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.829340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>-1.586025</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.511880</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>1.040981e+00</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>0.539054</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>0.912948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1.782424</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>0.281997</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>1.008578</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>5.903487e-01</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>1.901114</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.293951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.203480</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.446842</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.390846e-02</td>\n",
              "      <td>-0.478205</td>\n",
              "      <td>0.766064</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.500444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>-0.014054</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.444777</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>0.162199</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>-6.386489e-01</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>-0.141976</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>0.538678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>-0.238646</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.447739e+00</td>\n",
              "      <td>-0.478205</td>\n",
              "      <td>0.539054</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-0.764811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-0.491279</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.171536</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>0.585389</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-3.666809e-03</td>\n",
              "      <td>-0.090900</td>\n",
              "      <td>0.085034</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.545412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>-1.417603</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>-0.684180</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>7.535660e-09</td>\n",
              "      <td>0.199578</td>\n",
              "      <td>-1.504036</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.467899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>1.614001</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.326388</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-1.107370</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.171215e+00</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>1.674104</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-0.558318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>209 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age   anaemia  creatinine_phosphokinase  ...       sex   smoking      time\n",
              "224 -0.238646 -0.871105                  0.000166  ...  0.735688 -0.687682  0.964571\n",
              "68   0.771889 -0.871105                 -0.434454  ... -1.359272 -0.687682 -0.829340\n",
              "222 -1.586025  1.147968                 -0.511880  ...  0.735688  1.454161  0.912948\n",
              "37   1.782424  1.147968                  0.281997  ... -1.359272 -0.687682 -1.293951\n",
              "16   2.203480  1.147968                 -0.446842  ...  0.735688 -0.687682 -1.500444\n",
              "..        ...       ...                       ...  ...       ...       ...       ...\n",
              "188 -0.014054  1.147968                 -0.444777  ... -1.359272 -0.687682  0.538678\n",
              "71  -0.238646 -0.871105                  0.000166  ...  0.735688  1.454161 -0.764811\n",
              "106 -0.491279 -0.871105                  0.171536  ...  0.735688 -0.687682 -0.545412\n",
              "270 -1.417603 -0.871105                  0.000166  ...  0.735688  1.454161  1.467899\n",
              "102  1.614001 -0.871105                  0.326388  ...  0.735688  1.454161 -0.558318\n",
              "\n",
              "[209 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "5dJclsJ_kGAy",
        "outputId": "9c9f4081-e1d3-48a2-81b9-a3344c1a250a"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0.771889</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>0.162199</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-2.174896e+00</td>\n",
              "      <td>1.264666</td>\n",
              "      <td>-0.141976</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.545334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>-0.912335</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.293022</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>1.010256e+00</td>\n",
              "      <td>-0.478205</td>\n",
              "      <td>0.766064</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.416276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>-1.333392</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>1.920336</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>-0.684180</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>7.234901e-01</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>0.539054</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.016273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.614001</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.473683</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>1.276539e+00</td>\n",
              "      <td>7.752020</td>\n",
              "      <td>-0.823006</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-1.552067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>-1.586025</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.495362</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>0.162199</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-2.699496e-01</td>\n",
              "      <td>-0.187726</td>\n",
              "      <td>0.766064</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.726094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>-1.249180</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.141598</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>0.162199</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>7.535660e-09</td>\n",
              "      <td>-0.207091</td>\n",
              "      <td>0.085034</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.300201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>2.035057</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>5.471619</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-2.084997e-01</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>-1.050016</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-0.751905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.782424</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.209401</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>1.008578</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-2.215863e+00</td>\n",
              "      <td>-0.090900</td>\n",
              "      <td>-0.141976</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.513350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.192945</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.517041</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>1.071706e+00</td>\n",
              "      <td>2.523407</td>\n",
              "      <td>-1.277026</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-1.552067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>-0.912335</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.342574</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-1.107370</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.390846e-02</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>-0.141976</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-0.132425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age   anaemia  creatinine_phosphokinase  ...       sex   smoking      time\n",
              "281  0.771889 -0.871105                  0.000166  ...  0.735688  1.454161  1.545334\n",
              "265 -0.912335  1.147968                 -0.293022  ...  0.735688  1.454161  1.416276\n",
              "164 -1.333392 -0.871105                  1.920336  ...  0.735688 -0.687682 -0.016273\n",
              "9    1.614001  1.147968                 -0.473683  ...  0.735688  1.454161 -1.552067\n",
              "77  -1.586025 -0.871105                 -0.495362  ...  0.735688 -0.687682 -0.726094\n",
              "..        ...       ...                       ...  ...       ...       ...       ...\n",
              "132 -1.249180 -0.871105                  0.141598  ... -1.359272 -0.687682 -0.300201\n",
              "72   2.035057 -0.871105                  5.471619  ...  0.735688  1.454161 -0.751905\n",
              "15   1.782424  1.147968                 -0.209401  ...  0.735688 -0.687682 -1.513350\n",
              "10   1.192945  1.147968                 -0.517041  ...  0.735688  1.454161 -1.552067\n",
              "157 -0.912335 -0.871105                 -0.342574  ...  0.735688  1.454161 -0.132425\n",
              "\n",
              "[90 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNIazSfijlQI",
        "outputId": "1e0da8bc-1dac-48ac-9245-ce2ef4732ecb"
      },
      "source": [
        "# Initialising the NN\n",
        "model = Sequential()\n",
        "\n",
        "# layers\n",
        "model.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
        "model.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 500, validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 0.6928 - accuracy: 0.7020 - val_loss: 0.6914 - val_accuracy: 0.7857\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6915 - accuracy: 0.7301 - val_loss: 0.6898 - val_accuracy: 0.7857\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.6971 - val_loss: 0.6881 - val_accuracy: 0.7857\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6887 - accuracy: 0.7418 - val_loss: 0.6865 - val_accuracy: 0.7857\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.7232 - val_loss: 0.6848 - val_accuracy: 0.7857\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6871 - accuracy: 0.7002 - val_loss: 0.6831 - val_accuracy: 0.7857\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6854 - accuracy: 0.7159 - val_loss: 0.6814 - val_accuracy: 0.7857\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.7222 - val_loss: 0.6795 - val_accuracy: 0.7857\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.6755 - val_loss: 0.6777 - val_accuracy: 0.7857\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.7114 - val_loss: 0.6756 - val_accuracy: 0.7857\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.7401 - val_loss: 0.6734 - val_accuracy: 0.7857\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.6948 - val_loss: 0.6710 - val_accuracy: 0.7857\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.6918 - val_loss: 0.6684 - val_accuracy: 0.7857\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6753 - accuracy: 0.6986 - val_loss: 0.6653 - val_accuracy: 0.7857\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6715 - accuracy: 0.7127 - val_loss: 0.6617 - val_accuracy: 0.7857\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6662 - accuracy: 0.7356 - val_loss: 0.6577 - val_accuracy: 0.7857\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6667 - accuracy: 0.6991 - val_loss: 0.6531 - val_accuracy: 0.7857\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6674 - accuracy: 0.6641 - val_loss: 0.6474 - val_accuracy: 0.7857\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6617 - accuracy: 0.6729 - val_loss: 0.6401 - val_accuracy: 0.7857\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6499 - accuracy: 0.7060 - val_loss: 0.6313 - val_accuracy: 0.7857\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6436 - accuracy: 0.6969 - val_loss: 0.6208 - val_accuracy: 0.7857\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6322 - accuracy: 0.7064 - val_loss: 0.6085 - val_accuracy: 0.7857\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6178 - accuracy: 0.7098 - val_loss: 0.5938 - val_accuracy: 0.7857\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6094 - accuracy: 0.6897 - val_loss: 0.5769 - val_accuracy: 0.7857\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6006 - accuracy: 0.6697 - val_loss: 0.5580 - val_accuracy: 0.7857\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5727 - accuracy: 0.7120 - val_loss: 0.5374 - val_accuracy: 0.7857\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5490 - accuracy: 0.6953 - val_loss: 0.5151 - val_accuracy: 0.7857\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5196 - accuracy: 0.7241 - val_loss: 0.4923 - val_accuracy: 0.7857\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4871 - accuracy: 0.7453 - val_loss: 0.4690 - val_accuracy: 0.7857\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4668 - accuracy: 0.7441 - val_loss: 0.4477 - val_accuracy: 0.7857\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5065 - accuracy: 0.6495 - val_loss: 0.4290 - val_accuracy: 0.7857\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4492 - accuracy: 0.7098 - val_loss: 0.4118 - val_accuracy: 0.7857\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4342 - accuracy: 0.7218 - val_loss: 0.3967 - val_accuracy: 0.7857\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.7089 - val_loss: 0.3843 - val_accuracy: 0.7857\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4029 - accuracy: 0.7145 - val_loss: 0.3729 - val_accuracy: 0.7857\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.6568 - val_loss: 0.3645 - val_accuracy: 0.7857\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4170 - accuracy: 0.6941 - val_loss: 0.3570 - val_accuracy: 0.7857\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4192 - accuracy: 0.6943 - val_loss: 0.3520 - val_accuracy: 0.7857\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4304 - accuracy: 0.6527 - val_loss: 0.3472 - val_accuracy: 0.7857\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3981 - accuracy: 0.7060 - val_loss: 0.3427 - val_accuracy: 0.7857\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3788 - accuracy: 0.7161 - val_loss: 0.3391 - val_accuracy: 0.8333\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3870 - accuracy: 0.7885 - val_loss: 0.3375 - val_accuracy: 0.8571\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.8605 - val_loss: 0.3354 - val_accuracy: 0.8810\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3559 - accuracy: 0.8629 - val_loss: 0.3332 - val_accuracy: 0.8810\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3598 - accuracy: 0.8874 - val_loss: 0.3318 - val_accuracy: 0.8810\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3769 - accuracy: 0.8717 - val_loss: 0.3309 - val_accuracy: 0.8810\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3528 - accuracy: 0.8795 - val_loss: 0.3297 - val_accuracy: 0.8571\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3864 - accuracy: 0.8696 - val_loss: 0.3290 - val_accuracy: 0.8571\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3351 - accuracy: 0.8729 - val_loss: 0.3277 - val_accuracy: 0.8571\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.8867 - val_loss: 0.3267 - val_accuracy: 0.8571\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3253 - accuracy: 0.8973 - val_loss: 0.3269 - val_accuracy: 0.8333\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3095 - accuracy: 0.8926 - val_loss: 0.3273 - val_accuracy: 0.8333\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3409 - accuracy: 0.8897 - val_loss: 0.3279 - val_accuracy: 0.8333\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3247 - accuracy: 0.8720 - val_loss: 0.3286 - val_accuracy: 0.8333\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3131 - accuracy: 0.8753 - val_loss: 0.3286 - val_accuracy: 0.8333\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3309 - accuracy: 0.8795 - val_loss: 0.3280 - val_accuracy: 0.8333\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3213 - accuracy: 0.8826 - val_loss: 0.3282 - val_accuracy: 0.8333\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3179 - accuracy: 0.8835 - val_loss: 0.3305 - val_accuracy: 0.8333\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2981 - accuracy: 0.8735 - val_loss: 0.3335 - val_accuracy: 0.8333\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3113 - accuracy: 0.8817 - val_loss: 0.3336 - val_accuracy: 0.8333\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2913 - accuracy: 0.9124 - val_loss: 0.3345 - val_accuracy: 0.8095\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3115 - accuracy: 0.8862 - val_loss: 0.3371 - val_accuracy: 0.8095\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2839 - accuracy: 0.8981 - val_loss: 0.3417 - val_accuracy: 0.8095\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2596 - accuracy: 0.9126 - val_loss: 0.3454 - val_accuracy: 0.7857\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2674 - accuracy: 0.9198 - val_loss: 0.3474 - val_accuracy: 0.7857\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2691 - accuracy: 0.8977 - val_loss: 0.3489 - val_accuracy: 0.7857\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2748 - accuracy: 0.8999 - val_loss: 0.3511 - val_accuracy: 0.7857\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2460 - accuracy: 0.9193 - val_loss: 0.3542 - val_accuracy: 0.7857\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2770 - accuracy: 0.8955 - val_loss: 0.3596 - val_accuracy: 0.7857\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2515 - accuracy: 0.9202 - val_loss: 0.3645 - val_accuracy: 0.7857\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2609 - accuracy: 0.9138 - val_loss: 0.3693 - val_accuracy: 0.7857\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2368 - accuracy: 0.9228 - val_loss: 0.3740 - val_accuracy: 0.7857\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2244 - accuracy: 0.9179 - val_loss: 0.3826 - val_accuracy: 0.7857\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2849 - accuracy: 0.8978 - val_loss: 0.3878 - val_accuracy: 0.7857\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2867 - accuracy: 0.8865 - val_loss: 0.3948 - val_accuracy: 0.7857\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2532 - accuracy: 0.9179 - val_loss: 0.3981 - val_accuracy: 0.7857\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2636 - accuracy: 0.9077 - val_loss: 0.4000 - val_accuracy: 0.7857\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2210 - accuracy: 0.9316 - val_loss: 0.4023 - val_accuracy: 0.7857\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2599 - accuracy: 0.8992 - val_loss: 0.4049 - val_accuracy: 0.7857\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2424 - accuracy: 0.9064 - val_loss: 0.4104 - val_accuracy: 0.7857\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2218 - accuracy: 0.9252 - val_loss: 0.4129 - val_accuracy: 0.7857\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2138 - accuracy: 0.9330 - val_loss: 0.4167 - val_accuracy: 0.7857\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2211 - accuracy: 0.9208 - val_loss: 0.4209 - val_accuracy: 0.7857\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2034 - accuracy: 0.9319 - val_loss: 0.4245 - val_accuracy: 0.7857\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2124 - accuracy: 0.9291 - val_loss: 0.4277 - val_accuracy: 0.7857\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1998 - accuracy: 0.9293 - val_loss: 0.4318 - val_accuracy: 0.7857\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2316 - accuracy: 0.9137 - val_loss: 0.4350 - val_accuracy: 0.7857\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1882 - accuracy: 0.9263 - val_loss: 0.4382 - val_accuracy: 0.7857\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.9172 - val_loss: 0.4392 - val_accuracy: 0.7857\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2168 - accuracy: 0.9193 - val_loss: 0.4413 - val_accuracy: 0.7619\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2209 - accuracy: 0.9172 - val_loss: 0.4459 - val_accuracy: 0.7619\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1915 - accuracy: 0.9256 - val_loss: 0.4515 - val_accuracy: 0.7619\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2240 - accuracy: 0.9116 - val_loss: 0.4561 - val_accuracy: 0.7619\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1895 - accuracy: 0.9345 - val_loss: 0.4623 - val_accuracy: 0.7619\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1966 - accuracy: 0.9336 - val_loss: 0.4659 - val_accuracy: 0.7857\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1843 - accuracy: 0.9191 - val_loss: 0.4683 - val_accuracy: 0.8095\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2173 - accuracy: 0.9276 - val_loss: 0.4680 - val_accuracy: 0.8095\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2192 - accuracy: 0.9237 - val_loss: 0.4690 - val_accuracy: 0.8095\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1776 - accuracy: 0.9405 - val_loss: 0.4715 - val_accuracy: 0.8095\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1881 - accuracy: 0.9380 - val_loss: 0.4743 - val_accuracy: 0.8095\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1703 - accuracy: 0.9533 - val_loss: 0.4836 - val_accuracy: 0.8095\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2332 - accuracy: 0.9207 - val_loss: 0.4918 - val_accuracy: 0.7857\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2159 - accuracy: 0.9211 - val_loss: 0.4946 - val_accuracy: 0.7857\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1878 - accuracy: 0.9479 - val_loss: 0.4967 - val_accuracy: 0.7857\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1944 - accuracy: 0.9423 - val_loss: 0.4990 - val_accuracy: 0.7857\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2025 - accuracy: 0.9364 - val_loss: 0.5048 - val_accuracy: 0.7857\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1923 - accuracy: 0.9302 - val_loss: 0.5106 - val_accuracy: 0.7857\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2050 - accuracy: 0.9528 - val_loss: 0.5126 - val_accuracy: 0.7857\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1926 - accuracy: 0.9416 - val_loss: 0.5125 - val_accuracy: 0.7857\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1786 - accuracy: 0.9399 - val_loss: 0.5134 - val_accuracy: 0.7857\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2178 - accuracy: 0.9208 - val_loss: 0.5119 - val_accuracy: 0.7857\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2076 - accuracy: 0.9319 - val_loss: 0.5127 - val_accuracy: 0.8095\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2044 - accuracy: 0.9316 - val_loss: 0.5150 - val_accuracy: 0.8095\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2186 - accuracy: 0.9327 - val_loss: 0.5179 - val_accuracy: 0.8095\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1643 - accuracy: 0.9423 - val_loss: 0.5212 - val_accuracy: 0.8095\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1910 - accuracy: 0.9409 - val_loss: 0.5250 - val_accuracy: 0.8095\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2338 - accuracy: 0.9234 - val_loss: 0.5276 - val_accuracy: 0.8095\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1652 - accuracy: 0.9502 - val_loss: 0.5313 - val_accuracy: 0.8095\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1730 - accuracy: 0.9451 - val_loss: 0.5316 - val_accuracy: 0.8095\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1845 - accuracy: 0.9409 - val_loss: 0.5311 - val_accuracy: 0.8095\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1851 - accuracy: 0.9327 - val_loss: 0.5298 - val_accuracy: 0.8095\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1773 - accuracy: 0.9490 - val_loss: 0.5326 - val_accuracy: 0.8333\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9382 - val_loss: 0.5354 - val_accuracy: 0.8333\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1881 - accuracy: 0.9423 - val_loss: 0.5395 - val_accuracy: 0.8333\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1922 - accuracy: 0.9301 - val_loss: 0.5423 - val_accuracy: 0.8095\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1821 - accuracy: 0.9475 - val_loss: 0.5455 - val_accuracy: 0.8095\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2528 - accuracy: 0.9308 - val_loss: 0.5483 - val_accuracy: 0.8333\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1434 - accuracy: 0.9559 - val_loss: 0.5524 - val_accuracy: 0.8333\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1731 - accuracy: 0.9501 - val_loss: 0.5511 - val_accuracy: 0.8333\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9401 - val_loss: 0.5522 - val_accuracy: 0.8333\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1887 - accuracy: 0.9360 - val_loss: 0.5555 - val_accuracy: 0.8095\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1736 - accuracy: 0.9353 - val_loss: 0.5569 - val_accuracy: 0.8333\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1936 - accuracy: 0.9319 - val_loss: 0.5577 - val_accuracy: 0.8333\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 0.9423 - val_loss: 0.5662 - val_accuracy: 0.8095\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2236 - accuracy: 0.9297 - val_loss: 0.5724 - val_accuracy: 0.8095\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2077 - accuracy: 0.9399 - val_loss: 0.5746 - val_accuracy: 0.8095\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1849 - accuracy: 0.9382 - val_loss: 0.5783 - val_accuracy: 0.7857\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1539 - accuracy: 0.9531 - val_loss: 0.5844 - val_accuracy: 0.7857\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1986 - accuracy: 0.9241 - val_loss: 0.5854 - val_accuracy: 0.7857\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1383 - accuracy: 0.9510 - val_loss: 0.5881 - val_accuracy: 0.8095\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1835 - accuracy: 0.9375 - val_loss: 0.5856 - val_accuracy: 0.8333\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1947 - accuracy: 0.9178 - val_loss: 0.5882 - val_accuracy: 0.8333\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1542 - accuracy: 0.9481 - val_loss: 0.5933 - val_accuracy: 0.8095\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1293 - accuracy: 0.9564 - val_loss: 0.6029 - val_accuracy: 0.7619\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1377 - accuracy: 0.9457 - val_loss: 0.6058 - val_accuracy: 0.7619\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1583 - accuracy: 0.9572 - val_loss: 0.6069 - val_accuracy: 0.7857\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1903 - accuracy: 0.9339 - val_loss: 0.6084 - val_accuracy: 0.7857\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1572 - accuracy: 0.9420 - val_loss: 0.6116 - val_accuracy: 0.7857\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1137 - accuracy: 0.9663 - val_loss: 0.6162 - val_accuracy: 0.7857\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.6175 - val_accuracy: 0.7857\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1232 - accuracy: 0.9550 - val_loss: 0.6191 - val_accuracy: 0.7857\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1348 - accuracy: 0.9624 - val_loss: 0.6217 - val_accuracy: 0.7857\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1459 - accuracy: 0.9594 - val_loss: 0.6230 - val_accuracy: 0.7857\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1601 - accuracy: 0.9539 - val_loss: 0.6312 - val_accuracy: 0.7619\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1771 - accuracy: 0.9312 - val_loss: 0.6352 - val_accuracy: 0.7619\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1624 - accuracy: 0.9395 - val_loss: 0.6391 - val_accuracy: 0.7619\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1359 - accuracy: 0.9641 - val_loss: 0.6459 - val_accuracy: 0.7619\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1309 - accuracy: 0.9615 - val_loss: 0.6498 - val_accuracy: 0.7619\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1410 - accuracy: 0.9624 - val_loss: 0.6519 - val_accuracy: 0.7619\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1626 - accuracy: 0.9576 - val_loss: 0.6529 - val_accuracy: 0.7619\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1279 - accuracy: 0.9533 - val_loss: 0.6505 - val_accuracy: 0.7857\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1443 - accuracy: 0.9628 - val_loss: 0.6462 - val_accuracy: 0.7857\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1160 - accuracy: 0.9695 - val_loss: 0.6474 - val_accuracy: 0.7857\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1199 - accuracy: 0.9661 - val_loss: 0.6521 - val_accuracy: 0.7857\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1458 - accuracy: 0.9572 - val_loss: 0.6596 - val_accuracy: 0.7857\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1366 - accuracy: 0.9557 - val_loss: 0.6659 - val_accuracy: 0.7857\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1401 - accuracy: 0.9591 - val_loss: 0.6717 - val_accuracy: 0.7619\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1158 - accuracy: 0.9730 - val_loss: 0.6744 - val_accuracy: 0.7857\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1600 - accuracy: 0.9520 - val_loss: 0.6761 - val_accuracy: 0.7857\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1686 - accuracy: 0.9435 - val_loss: 0.6772 - val_accuracy: 0.7857\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1340 - accuracy: 0.9572 - val_loss: 0.6883 - val_accuracy: 0.7619\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1565 - accuracy: 0.9507 - val_loss: 0.6934 - val_accuracy: 0.7619\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2037 - accuracy: 0.9371 - val_loss: 0.6975 - val_accuracy: 0.7619\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1258 - accuracy: 0.9498 - val_loss: 0.6991 - val_accuracy: 0.7619\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1431 - accuracy: 0.9505 - val_loss: 0.6978 - val_accuracy: 0.7619\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1405 - accuracy: 0.9535 - val_loss: 0.7004 - val_accuracy: 0.7619\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1181 - accuracy: 0.9745 - val_loss: 0.7030 - val_accuracy: 0.7619\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1297 - accuracy: 0.9635 - val_loss: 0.7028 - val_accuracy: 0.8095\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1229 - accuracy: 0.9580 - val_loss: 0.7057 - val_accuracy: 0.8095\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1551 - accuracy: 0.9498 - val_loss: 0.7079 - val_accuracy: 0.8095\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1267 - accuracy: 0.9632 - val_loss: 0.7127 - val_accuracy: 0.7857\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.9416 - val_loss: 0.7158 - val_accuracy: 0.8095\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1279 - accuracy: 0.9633 - val_loss: 0.7184 - val_accuracy: 0.8095\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1216 - accuracy: 0.9602 - val_loss: 0.7216 - val_accuracy: 0.8095\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1515 - accuracy: 0.9546 - val_loss: 0.7240 - val_accuracy: 0.8095\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9524 - val_loss: 0.7260 - val_accuracy: 0.8095\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1538 - accuracy: 0.9498 - val_loss: 0.7301 - val_accuracy: 0.8095\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.9566 - val_loss: 0.7365 - val_accuracy: 0.8095\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1161 - accuracy: 0.9600 - val_loss: 0.7433 - val_accuracy: 0.7619\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1383 - accuracy: 0.9635 - val_loss: 0.7461 - val_accuracy: 0.7619\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9472 - val_loss: 0.7481 - val_accuracy: 0.7619\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0993 - accuracy: 0.9626 - val_loss: 0.7487 - val_accuracy: 0.7857\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1585 - accuracy: 0.9473 - val_loss: 0.7422 - val_accuracy: 0.8095\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1240 - accuracy: 0.9639 - val_loss: 0.7429 - val_accuracy: 0.8095\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1162 - accuracy: 0.9653 - val_loss: 0.7477 - val_accuracy: 0.8095\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1388 - accuracy: 0.9464 - val_loss: 0.7527 - val_accuracy: 0.8095\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9611 - val_loss: 0.7577 - val_accuracy: 0.7857\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1229 - accuracy: 0.9580 - val_loss: 0.7576 - val_accuracy: 0.8095\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1215 - accuracy: 0.9628 - val_loss: 0.7580 - val_accuracy: 0.8095\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1375 - accuracy: 0.9598 - val_loss: 0.7590 - val_accuracy: 0.7857\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1196 - accuracy: 0.9535 - val_loss: 0.7601 - val_accuracy: 0.7857\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1444 - accuracy: 0.9580 - val_loss: 0.7603 - val_accuracy: 0.8095\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1215 - accuracy: 0.9591 - val_loss: 0.7628 - val_accuracy: 0.8095\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1001 - accuracy: 0.9684 - val_loss: 0.7668 - val_accuracy: 0.8095\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1091 - accuracy: 0.9591 - val_loss: 0.7703 - val_accuracy: 0.8095\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1103 - accuracy: 0.9598 - val_loss: 0.7733 - val_accuracy: 0.8095\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1541 - accuracy: 0.9531 - val_loss: 0.7749 - val_accuracy: 0.8095\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0946 - accuracy: 0.9688 - val_loss: 0.7810 - val_accuracy: 0.8095\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1017 - accuracy: 0.9546 - val_loss: 0.7840 - val_accuracy: 0.8095\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1041 - accuracy: 0.9732 - val_loss: 0.7902 - val_accuracy: 0.7857\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1754 - accuracy: 0.9345 - val_loss: 0.7884 - val_accuracy: 0.8095\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1051 - accuracy: 0.9650 - val_loss: 0.7917 - val_accuracy: 0.8095\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1461 - accuracy: 0.9496 - val_loss: 0.7949 - val_accuracy: 0.8095\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1482 - accuracy: 0.9488 - val_loss: 0.7957 - val_accuracy: 0.8095\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1455 - accuracy: 0.9487 - val_loss: 0.7966 - val_accuracy: 0.8095\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.9661 - val_loss: 0.7989 - val_accuracy: 0.8095\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1105 - accuracy: 0.9639 - val_loss: 0.7999 - val_accuracy: 0.8095\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1042 - accuracy: 0.9626 - val_loss: 0.8017 - val_accuracy: 0.8095\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1075 - accuracy: 0.9693 - val_loss: 0.8034 - val_accuracy: 0.8095\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.9739 - val_loss: 0.8056 - val_accuracy: 0.8095\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1217 - accuracy: 0.9591 - val_loss: 0.8074 - val_accuracy: 0.8095\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1256 - accuracy: 0.9648 - val_loss: 0.8098 - val_accuracy: 0.8095\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0982 - accuracy: 0.9767 - val_loss: 0.8127 - val_accuracy: 0.8095\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1055 - accuracy: 0.9595 - val_loss: 0.8135 - val_accuracy: 0.8095\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1103 - accuracy: 0.9658 - val_loss: 0.8165 - val_accuracy: 0.8095\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1178 - accuracy: 0.9622 - val_loss: 0.8201 - val_accuracy: 0.8095\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9570 - val_loss: 0.8219 - val_accuracy: 0.8095\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 0.9747 - val_loss: 0.8240 - val_accuracy: 0.8095\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1353 - accuracy: 0.9509 - val_loss: 0.8254 - val_accuracy: 0.8095\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9524 - val_loss: 0.8283 - val_accuracy: 0.8095\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1153 - accuracy: 0.9498 - val_loss: 0.8338 - val_accuracy: 0.8095\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9557 - val_loss: 0.8382 - val_accuracy: 0.8095\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0827 - accuracy: 0.9732 - val_loss: 0.8426 - val_accuracy: 0.8095\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1516 - accuracy: 0.9494 - val_loss: 0.8446 - val_accuracy: 0.8095\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0864 - accuracy: 0.9678 - val_loss: 0.8492 - val_accuracy: 0.8095\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1119 - accuracy: 0.9554 - val_loss: 0.8512 - val_accuracy: 0.8095\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0893 - accuracy: 0.9654 - val_loss: 0.8520 - val_accuracy: 0.8095\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9390 - val_loss: 0.8539 - val_accuracy: 0.8095\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.9598 - val_loss: 0.8635 - val_accuracy: 0.7857\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0954 - accuracy: 0.9661 - val_loss: 0.8686 - val_accuracy: 0.7857\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1116 - accuracy: 0.9629 - val_loss: 0.8705 - val_accuracy: 0.7857\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1087 - accuracy: 0.9615 - val_loss: 0.8705 - val_accuracy: 0.8095\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0974 - accuracy: 0.9661 - val_loss: 0.8716 - val_accuracy: 0.8095\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0881 - accuracy: 0.9643 - val_loss: 0.8738 - val_accuracy: 0.8095\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1430 - accuracy: 0.9557 - val_loss: 0.8755 - val_accuracy: 0.8095\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0873 - accuracy: 0.9628 - val_loss: 0.8798 - val_accuracy: 0.8095\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1077 - accuracy: 0.9618 - val_loss: 0.8831 - val_accuracy: 0.8095\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0987 - accuracy: 0.9565 - val_loss: 0.8872 - val_accuracy: 0.8095\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.9603 - val_loss: 0.8921 - val_accuracy: 0.8095\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1429 - accuracy: 0.9405 - val_loss: 0.8943 - val_accuracy: 0.8095\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1401 - accuracy: 0.9520 - val_loss: 0.8961 - val_accuracy: 0.8095\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1272 - accuracy: 0.9531 - val_loss: 0.9002 - val_accuracy: 0.8095\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0984 - accuracy: 0.9613 - val_loss: 0.9033 - val_accuracy: 0.8095\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0936 - accuracy: 0.9626 - val_loss: 0.9056 - val_accuracy: 0.8095\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1433 - accuracy: 0.9490 - val_loss: 0.9046 - val_accuracy: 0.8095\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0958 - accuracy: 0.9598 - val_loss: 0.9067 - val_accuracy: 0.8095\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1059 - accuracy: 0.9624 - val_loss: 0.9089 - val_accuracy: 0.8095\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0973 - accuracy: 0.9591 - val_loss: 0.9113 - val_accuracy: 0.8095\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0980 - accuracy: 0.9617 - val_loss: 0.9129 - val_accuracy: 0.8095\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1561 - accuracy: 0.9304 - val_loss: 0.9149 - val_accuracy: 0.8095\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1111 - accuracy: 0.9539 - val_loss: 0.9171 - val_accuracy: 0.8095\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 0.9719 - val_loss: 0.9209 - val_accuracy: 0.8095\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1286 - accuracy: 0.9505 - val_loss: 0.9209 - val_accuracy: 0.8095\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1294 - accuracy: 0.9462 - val_loss: 0.9224 - val_accuracy: 0.8095\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1184 - accuracy: 0.9453 - val_loss: 0.9247 - val_accuracy: 0.8095\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1022 - accuracy: 0.9661 - val_loss: 0.9266 - val_accuracy: 0.8095\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1073 - accuracy: 0.9598 - val_loss: 0.9311 - val_accuracy: 0.8095\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1101 - accuracy: 0.9546 - val_loss: 0.9378 - val_accuracy: 0.8095\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0758 - accuracy: 0.9743 - val_loss: 0.9428 - val_accuracy: 0.8095\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1130 - accuracy: 0.9528 - val_loss: 0.9439 - val_accuracy: 0.8095\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1042 - accuracy: 0.9672 - val_loss: 0.9456 - val_accuracy: 0.8095\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1014 - accuracy: 0.9635 - val_loss: 0.9449 - val_accuracy: 0.8095\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9449 - val_loss: 0.9450 - val_accuracy: 0.8095\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0883 - accuracy: 0.9673 - val_loss: 0.9476 - val_accuracy: 0.8095\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0765 - accuracy: 0.9761 - val_loss: 0.9501 - val_accuracy: 0.8095\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1306 - accuracy: 0.9438 - val_loss: 0.9493 - val_accuracy: 0.8095\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1285 - accuracy: 0.9464 - val_loss: 0.9504 - val_accuracy: 0.8095\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1014 - accuracy: 0.9595 - val_loss: 0.9539 - val_accuracy: 0.8095\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1432 - accuracy: 0.9431 - val_loss: 0.9571 - val_accuracy: 0.8095\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0839 - accuracy: 0.9695 - val_loss: 0.9628 - val_accuracy: 0.8095\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0881 - accuracy: 0.9580 - val_loss: 0.9671 - val_accuracy: 0.8095\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1085 - accuracy: 0.9540 - val_loss: 0.9692 - val_accuracy: 0.8095\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1108 - accuracy: 0.9561 - val_loss: 0.9709 - val_accuracy: 0.8095\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1121 - accuracy: 0.9487 - val_loss: 0.9758 - val_accuracy: 0.8095\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1043 - accuracy: 0.9513 - val_loss: 0.9803 - val_accuracy: 0.8095\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1070 - accuracy: 0.9427 - val_loss: 0.9846 - val_accuracy: 0.8095\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1103 - accuracy: 0.9531 - val_loss: 0.9888 - val_accuracy: 0.8095\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1060 - accuracy: 0.9472 - val_loss: 0.9901 - val_accuracy: 0.8095\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0733 - accuracy: 0.9659 - val_loss: 0.9946 - val_accuracy: 0.8095\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0805 - accuracy: 0.9706 - val_loss: 0.9971 - val_accuracy: 0.8095\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1208 - accuracy: 0.9509 - val_loss: 1.0013 - val_accuracy: 0.7857\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9635 - val_loss: 1.0088 - val_accuracy: 0.7619\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1342 - accuracy: 0.9453 - val_loss: 1.0094 - val_accuracy: 0.7619\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 0.9622 - val_loss: 1.0090 - val_accuracy: 0.7857\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1064 - accuracy: 0.9509 - val_loss: 1.0115 - val_accuracy: 0.8095\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1257 - accuracy: 0.9516 - val_loss: 1.0112 - val_accuracy: 0.8095\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0731 - accuracy: 0.9758 - val_loss: 1.0142 - val_accuracy: 0.8095\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1183 - accuracy: 0.9606 - val_loss: 1.0152 - val_accuracy: 0.8095\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1113 - accuracy: 0.9583 - val_loss: 1.0201 - val_accuracy: 0.7857\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0766 - accuracy: 0.9706 - val_loss: 1.0240 - val_accuracy: 0.7619\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1062 - accuracy: 0.9613 - val_loss: 1.0242 - val_accuracy: 0.7857\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1042 - accuracy: 0.9591 - val_loss: 1.0275 - val_accuracy: 0.8095\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9585 - val_loss: 1.0288 - val_accuracy: 0.8095\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1013 - accuracy: 0.9505 - val_loss: 1.0216 - val_accuracy: 0.8095\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.9483 - val_loss: 1.0187 - val_accuracy: 0.8095\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0912 - accuracy: 0.9580 - val_loss: 1.0219 - val_accuracy: 0.8095\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9713 - val_loss: 1.0243 - val_accuracy: 0.8095\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0823 - accuracy: 0.9710 - val_loss: 1.0205 - val_accuracy: 0.8095\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0988 - accuracy: 0.9546 - val_loss: 1.0214 - val_accuracy: 0.8095\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1263 - accuracy: 0.9516 - val_loss: 1.0239 - val_accuracy: 0.8095\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1203 - accuracy: 0.9498 - val_loss: 1.0266 - val_accuracy: 0.8095\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1002 - accuracy: 0.9606 - val_loss: 1.0297 - val_accuracy: 0.8095\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0909 - accuracy: 0.9539 - val_loss: 1.0342 - val_accuracy: 0.8095\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1071 - accuracy: 0.9487 - val_loss: 1.0393 - val_accuracy: 0.7857\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0872 - accuracy: 0.9643 - val_loss: 1.0429 - val_accuracy: 0.7857\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0922 - accuracy: 0.9498 - val_loss: 1.0444 - val_accuracy: 0.8095\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0871 - accuracy: 0.9509 - val_loss: 1.0471 - val_accuracy: 0.8095\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0987 - accuracy: 0.9600 - val_loss: 1.0490 - val_accuracy: 0.8095\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1261 - accuracy: 0.9490 - val_loss: 1.0509 - val_accuracy: 0.8095\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.9745 - val_loss: 1.0541 - val_accuracy: 0.8095\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1299 - accuracy: 0.9390 - val_loss: 1.0475 - val_accuracy: 0.8095\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1045 - accuracy: 0.9524 - val_loss: 1.0503 - val_accuracy: 0.8095\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0892 - accuracy: 0.9632 - val_loss: 1.0540 - val_accuracy: 0.8095\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1109 - accuracy: 0.9453 - val_loss: 1.0579 - val_accuracy: 0.7857\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0980 - accuracy: 0.9554 - val_loss: 1.0608 - val_accuracy: 0.7857\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0898 - accuracy: 0.9572 - val_loss: 1.0659 - val_accuracy: 0.7619\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0958 - accuracy: 0.9628 - val_loss: 1.0665 - val_accuracy: 0.7619\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0834 - accuracy: 0.9535 - val_loss: 1.0681 - val_accuracy: 0.8095\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0947 - accuracy: 0.9613 - val_loss: 1.0700 - val_accuracy: 0.8095\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1014 - accuracy: 0.9565 - val_loss: 1.0716 - val_accuracy: 0.8095\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0764 - accuracy: 0.9673 - val_loss: 1.0743 - val_accuracy: 0.8095\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0907 - accuracy: 0.9565 - val_loss: 1.0763 - val_accuracy: 0.8095\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1268 - accuracy: 0.9496 - val_loss: 1.0780 - val_accuracy: 0.8095\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0820 - accuracy: 0.9661 - val_loss: 1.0812 - val_accuracy: 0.8095\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9661 - val_loss: 1.0834 - val_accuracy: 0.8095\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0909 - accuracy: 0.9544 - val_loss: 1.0857 - val_accuracy: 0.8095\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0803 - accuracy: 0.9673 - val_loss: 1.0812 - val_accuracy: 0.8095\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0901 - accuracy: 0.9639 - val_loss: 1.0811 - val_accuracy: 0.8095\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9670 - val_loss: 1.0828 - val_accuracy: 0.8095\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0983 - accuracy: 0.9555 - val_loss: 1.0850 - val_accuracy: 0.8095\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9706 - val_loss: 1.0858 - val_accuracy: 0.8095\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0865 - accuracy: 0.9524 - val_loss: 1.0866 - val_accuracy: 0.8095\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 1.0917 - val_accuracy: 0.7857\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0937 - accuracy: 0.9475 - val_loss: 1.1107 - val_accuracy: 0.7619\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0837 - accuracy: 0.9643 - val_loss: 1.1217 - val_accuracy: 0.7619\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1148 - accuracy: 0.9535 - val_loss: 1.1175 - val_accuracy: 0.7857\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0854 - accuracy: 0.9577 - val_loss: 1.1159 - val_accuracy: 0.7857\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0925 - accuracy: 0.9606 - val_loss: 1.1141 - val_accuracy: 0.7857\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1176 - accuracy: 0.9438 - val_loss: 1.1135 - val_accuracy: 0.7857\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0999 - accuracy: 0.9554 - val_loss: 1.1136 - val_accuracy: 0.7857\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0699 - accuracy: 0.9706 - val_loss: 1.1148 - val_accuracy: 0.7857\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0759 - accuracy: 0.9710 - val_loss: 1.1144 - val_accuracy: 0.7857\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0918 - accuracy: 0.9696 - val_loss: 1.1148 - val_accuracy: 0.7857\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0778 - accuracy: 0.9592 - val_loss: 1.1146 - val_accuracy: 0.7857\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0726 - accuracy: 0.9639 - val_loss: 1.1160 - val_accuracy: 0.7857\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0822 - accuracy: 0.9658 - val_loss: 1.1174 - val_accuracy: 0.7857\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0813 - accuracy: 0.9587 - val_loss: 1.1198 - val_accuracy: 0.8095\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0838 - accuracy: 0.9665 - val_loss: 1.1217 - val_accuracy: 0.8095\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0961 - accuracy: 0.9524 - val_loss: 1.1268 - val_accuracy: 0.8095\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0613 - accuracy: 0.9706 - val_loss: 1.1309 - val_accuracy: 0.8095\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0838 - accuracy: 0.9546 - val_loss: 1.1354 - val_accuracy: 0.8095\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1003 - accuracy: 0.9453 - val_loss: 1.1397 - val_accuracy: 0.8095\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9576 - val_loss: 1.1441 - val_accuracy: 0.8095\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0672 - accuracy: 0.9717 - val_loss: 1.1514 - val_accuracy: 0.8095\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0891 - accuracy: 0.9520 - val_loss: 1.1568 - val_accuracy: 0.8095\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0745 - accuracy: 0.9635 - val_loss: 1.1616 - val_accuracy: 0.8095\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0733 - accuracy: 0.9613 - val_loss: 1.1666 - val_accuracy: 0.8095\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9482 - val_loss: 1.1693 - val_accuracy: 0.8095\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0930 - accuracy: 0.9368 - val_loss: 1.1705 - val_accuracy: 0.8095\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0932 - accuracy: 0.9397 - val_loss: 1.1750 - val_accuracy: 0.8095\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0893 - accuracy: 0.9447 - val_loss: 1.1854 - val_accuracy: 0.8095\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0761 - accuracy: 0.9659 - val_loss: 1.1923 - val_accuracy: 0.7857\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9505 - val_loss: 1.1990 - val_accuracy: 0.7857\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1000 - accuracy: 0.9438 - val_loss: 1.2037 - val_accuracy: 0.7857\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0777 - accuracy: 0.9554 - val_loss: 1.2108 - val_accuracy: 0.7857\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9710 - val_loss: 1.2171 - val_accuracy: 0.7857\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0658 - accuracy: 0.9747 - val_loss: 1.2231 - val_accuracy: 0.7857\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0805 - accuracy: 0.9449 - val_loss: 1.2275 - val_accuracy: 0.7857\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0714 - accuracy: 0.9635 - val_loss: 1.2334 - val_accuracy: 0.8095\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0731 - accuracy: 0.9551 - val_loss: 1.2386 - val_accuracy: 0.7857\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0854 - accuracy: 0.9395 - val_loss: 1.2479 - val_accuracy: 0.7857\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0794 - accuracy: 0.9554 - val_loss: 1.2543 - val_accuracy: 0.7857\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0669 - accuracy: 0.9661 - val_loss: 1.2599 - val_accuracy: 0.7857\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0688 - accuracy: 0.9624 - val_loss: 1.2637 - val_accuracy: 0.8095\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0608 - accuracy: 0.9699 - val_loss: 1.2672 - val_accuracy: 0.8095\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0803 - accuracy: 0.9397 - val_loss: 1.2709 - val_accuracy: 0.8095\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0675 - accuracy: 0.9678 - val_loss: 1.2720 - val_accuracy: 0.7857\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9635 - val_loss: 1.2789 - val_accuracy: 0.7857\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0702 - accuracy: 0.9680 - val_loss: 1.2915 - val_accuracy: 0.7857\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.9531 - val_loss: 1.2965 - val_accuracy: 0.7857\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0612 - accuracy: 0.9747 - val_loss: 1.3041 - val_accuracy: 0.7857\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0630 - accuracy: 0.9717 - val_loss: 1.3083 - val_accuracy: 0.7857\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9576 - val_loss: 1.3170 - val_accuracy: 0.7857\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0631 - accuracy: 0.9810 - val_loss: 1.3249 - val_accuracy: 0.7857\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0638 - accuracy: 0.9710 - val_loss: 1.3341 - val_accuracy: 0.7857\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0712 - accuracy: 0.9583 - val_loss: 1.3401 - val_accuracy: 0.7857\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0629 - accuracy: 0.9624 - val_loss: 1.3447 - val_accuracy: 0.7857\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0665 - accuracy: 0.9576 - val_loss: 1.3499 - val_accuracy: 0.7857\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 0.9737 - val_loss: 1.3558 - val_accuracy: 0.7857\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9688 - val_loss: 1.3596 - val_accuracy: 0.8095\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.9643 - val_loss: 1.3672 - val_accuracy: 0.7857\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0690 - accuracy: 0.9613 - val_loss: 1.3771 - val_accuracy: 0.7857\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0626 - accuracy: 0.9576 - val_loss: 1.3911 - val_accuracy: 0.7857\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0677 - accuracy: 0.9643 - val_loss: 1.4021 - val_accuracy: 0.7857\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0523 - accuracy: 0.9804 - val_loss: 1.4120 - val_accuracy: 0.7857\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0607 - accuracy: 0.9702 - val_loss: 1.4210 - val_accuracy: 0.7857\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0564 - accuracy: 0.9676 - val_loss: 1.4285 - val_accuracy: 0.7857\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0570 - accuracy: 0.9669 - val_loss: 1.4322 - val_accuracy: 0.7857\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0601 - accuracy: 0.9676 - val_loss: 1.4407 - val_accuracy: 0.7857\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0640 - accuracy: 0.9632 - val_loss: 1.4523 - val_accuracy: 0.7857\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0527 - accuracy: 0.9771 - val_loss: 1.4606 - val_accuracy: 0.7857\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0740 - accuracy: 0.9516 - val_loss: 1.4675 - val_accuracy: 0.7857\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9737 - val_loss: 1.4742 - val_accuracy: 0.7857\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9609 - val_loss: 1.4766 - val_accuracy: 0.8095\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0581 - accuracy: 0.9766 - val_loss: 1.4810 - val_accuracy: 0.8095\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0546 - accuracy: 0.9678 - val_loss: 1.4888 - val_accuracy: 0.8095\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0454 - accuracy: 0.9696 - val_loss: 1.4981 - val_accuracy: 0.7857\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.9856 - val_loss: 1.5059 - val_accuracy: 0.7857\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9572 - val_loss: 1.5133 - val_accuracy: 0.8095\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.9688 - val_loss: 1.5194 - val_accuracy: 0.8095\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0374 - accuracy: 0.9775 - val_loss: 1.5261 - val_accuracy: 0.8095\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9555 - val_loss: 1.5328 - val_accuracy: 0.7857\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0537 - accuracy: 0.9665 - val_loss: 1.5353 - val_accuracy: 0.7857\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9676 - val_loss: 1.5437 - val_accuracy: 0.7857\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0648 - accuracy: 0.9635 - val_loss: 1.5607 - val_accuracy: 0.7857\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.9711 - val_loss: 1.5722 - val_accuracy: 0.7857\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9633 - val_loss: 1.5803 - val_accuracy: 0.7857\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0518 - accuracy: 0.9624 - val_loss: 1.5883 - val_accuracy: 0.7857\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0431 - accuracy: 0.9778 - val_loss: 1.5943 - val_accuracy: 0.7619\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0443 - accuracy: 0.9688 - val_loss: 1.5974 - val_accuracy: 0.7857\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0482 - accuracy: 0.9669 - val_loss: 1.6086 - val_accuracy: 0.7619\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0515 - accuracy: 0.9788 - val_loss: 1.6164 - val_accuracy: 0.7857\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0532 - accuracy: 0.9568 - val_loss: 1.6218 - val_accuracy: 0.7857\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0365 - accuracy: 0.9749 - val_loss: 1.6245 - val_accuracy: 0.7857\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0429 - accuracy: 0.9678 - val_loss: 1.6307 - val_accuracy: 0.7857\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.9624 - val_loss: 1.6342 - val_accuracy: 0.7857\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9814 - val_loss: 1.6398 - val_accuracy: 0.7857\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.9775 - val_loss: 1.6459 - val_accuracy: 0.7857\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.9825 - val_loss: 1.6528 - val_accuracy: 0.8095\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0396 - accuracy: 0.9743 - val_loss: 1.6578 - val_accuracy: 0.8095\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9751 - val_loss: 1.6600 - val_accuracy: 0.7857\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0470 - accuracy: 0.9782 - val_loss: 1.6625 - val_accuracy: 0.8095\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0565 - accuracy: 0.9661 - val_loss: 1.6685 - val_accuracy: 0.7857\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0384 - accuracy: 0.9844 - val_loss: 1.6777 - val_accuracy: 0.7857\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.9782 - val_loss: 1.6887 - val_accuracy: 0.7857\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9814 - val_loss: 1.6975 - val_accuracy: 0.7857\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0508 - accuracy: 0.9725 - val_loss: 1.7035 - val_accuracy: 0.7857\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0614 - accuracy: 0.9658 - val_loss: 1.7110 - val_accuracy: 0.7857\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 1.7146 - val_accuracy: 0.7857\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0492 - accuracy: 0.9743 - val_loss: 1.7150 - val_accuracy: 0.7857\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0533 - accuracy: 0.9728 - val_loss: 1.7167 - val_accuracy: 0.7857\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0409 - accuracy: 0.9788 - val_loss: 1.7234 - val_accuracy: 0.7857\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0437 - accuracy: 0.9807 - val_loss: 1.7324 - val_accuracy: 0.7857\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0457 - accuracy: 0.9673 - val_loss: 1.7412 - val_accuracy: 0.7857\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9773 - val_loss: 1.7479 - val_accuracy: 0.7857\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0408 - accuracy: 0.9762 - val_loss: 1.7547 - val_accuracy: 0.7857\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0387 - accuracy: 0.9762 - val_loss: 1.7607 - val_accuracy: 0.7857\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9706 - val_loss: 1.7653 - val_accuracy: 0.7857\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0478 - accuracy: 0.9792 - val_loss: 1.7690 - val_accuracy: 0.7857\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 0.9717 - val_loss: 1.7777 - val_accuracy: 0.7857\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 1.7864 - val_accuracy: 0.7857\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0438 - accuracy: 0.9717 - val_loss: 1.7954 - val_accuracy: 0.7857\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0428 - accuracy: 0.9797 - val_loss: 1.8096 - val_accuracy: 0.7619\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0428 - accuracy: 0.9810 - val_loss: 1.8211 - val_accuracy: 0.7619\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0631 - accuracy: 0.9531 - val_loss: 1.8254 - val_accuracy: 0.7619\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0395 - accuracy: 0.9795 - val_loss: 1.8282 - val_accuracy: 0.7619\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0471 - accuracy: 0.9732 - val_loss: 1.8352 - val_accuracy: 0.7857\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0383 - accuracy: 0.9663 - val_loss: 1.8399 - val_accuracy: 0.7857\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 0.9751 - val_loss: 1.8400 - val_accuracy: 0.7857\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0465 - accuracy: 0.9695 - val_loss: 1.8429 - val_accuracy: 0.7857\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0469 - accuracy: 0.9751 - val_loss: 1.8478 - val_accuracy: 0.7857\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 0.9836 - val_loss: 1.8558 - val_accuracy: 0.7857\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9737 - val_loss: 1.8606 - val_accuracy: 0.7857\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0426 - accuracy: 0.9754 - val_loss: 1.8620 - val_accuracy: 0.7857\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 1.8633 - val_accuracy: 0.7857\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0514 - accuracy: 0.9635 - val_loss: 1.8688 - val_accuracy: 0.7857\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9766 - val_loss: 1.8743 - val_accuracy: 0.7857\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0390 - accuracy: 0.9847 - val_loss: 1.8801 - val_accuracy: 0.7857\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9821 - val_loss: 1.8847 - val_accuracy: 0.7857\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0438 - accuracy: 0.9754 - val_loss: 1.8906 - val_accuracy: 0.7857\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9751 - val_loss: 1.8962 - val_accuracy: 0.7857\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9847 - val_loss: 1.8969 - val_accuracy: 0.7857\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9766 - val_loss: 1.9026 - val_accuracy: 0.7857\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0493 - accuracy: 0.9661 - val_loss: 1.9075 - val_accuracy: 0.7857\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0399 - accuracy: 0.9788 - val_loss: 1.9171 - val_accuracy: 0.7857\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0512 - accuracy: 0.9658 - val_loss: 1.9232 - val_accuracy: 0.7857\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0296 - accuracy: 0.9874 - val_loss: 1.9261 - val_accuracy: 0.7857\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 0.9728 - val_loss: 1.9305 - val_accuracy: 0.7857\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9710 - val_loss: 1.9338 - val_accuracy: 0.7857\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0452 - accuracy: 0.9769 - val_loss: 1.9393 - val_accuracy: 0.7857\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0419 - accuracy: 0.9684 - val_loss: 1.9444 - val_accuracy: 0.7857\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0412 - accuracy: 0.9688 - val_loss: 1.9482 - val_accuracy: 0.7857\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 0.9769 - val_loss: 1.9514 - val_accuracy: 0.7857\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0499 - accuracy: 0.9591 - val_loss: 1.9526 - val_accuracy: 0.7857\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0640 - accuracy: 0.9613 - val_loss: 1.9640 - val_accuracy: 0.7857\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0465 - accuracy: 0.9740 - val_loss: 1.9734 - val_accuracy: 0.7857\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0412 - accuracy: 0.9766 - val_loss: 1.9805 - val_accuracy: 0.7857\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9836 - val_loss: 1.9876 - val_accuracy: 0.7857\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0373 - accuracy: 0.9781 - val_loss: 1.9938 - val_accuracy: 0.7857\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0434 - accuracy: 0.9803 - val_loss: 1.9974 - val_accuracy: 0.7857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfjqDmRpjpFG",
        "outputId": "8a626258-6b46-4dfd-b852-b86d8d4caf64"
      },
      "source": [
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "print(\"\\n%s: %.2f%%\" % ('val_accuracy', val_accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "val_accuracy: 79.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyMWc8akjyxz"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "np.set_printoptions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "tH2Q5q5Rj4Jp",
        "outputId": "45d3c08a-022c-4470-a82e-70bb661e2d7a"
      },
      "source": [
        "cmap1 = sns.diverging_palette(275,150,  s=40, l=65, n=6)\n",
        "plt.subplots(figsize=(12,8))\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea14e05f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAHWCAYAAAAfEsOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7TfdX3n+9c7O9kBkwBBLkISIEoQAyLIxXpHixqmLbjasaJ1Kh3nUGeV1Z7pdE7xtAc7OM60upan03PoUVYXTue0lmPbaZtaLIMiqFU0USkQYiDhloRLgHDPZefyOX9kE38J+ewESLKz9fFY67f4fT+/7+f7+W7WIjzz/f2+v12ttQAAwK5MGu8TAADgwCUWAQDoEosAAHSJRQAAusQiAABdYhEAgC6xCAAwwVTVgqpaVlXLq+qyXbx+cVU9UlW3jD7+zcBrH66qu0YfH97tWr5nEQBg4qiqoSR3JnlXklVJFiX5QGvtjoF9Lk5yVmvt0p3mHp5kcZKzkrQk30tyZmvt8d56riwCAEws5yRZ3lq7u7U2kuSaJBfu4dz3JLm+tbZ2NBCvT7JgrAliEQBgYpmVZOXA9qrRsZ39QlXdWlV/VVVzXuDc7Sa/lDPdE797zR95nxvYIyc/cfZ4nwIwQXzoo2+s8T6HfdU4n/zAb/xqkksGhq5qrV31Ag/z90n+orW2sap+NcmfJnnnizmffR6LAADsudEwHCsOVyeZM7A9e3Rs8BiPDWz+SZJPDcw9d6e5N451Pt6GBgCYWBYlmVdVc6tqOMlFSRYO7lBVxwxsXpBk6ejz65K8u6pmVtXMJO8eHetyZREAYAJprW2uqkuzLfKGklzdWltSVVckWdxaW5jk16vqgiSbk6xNcvHo3LVV9YlsC84kuaK1tnas9cQiAMAE01q7Nsm1O41dPvD8Y0k+1pl7dZKr93Qtb0MDANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgDABFNVC6pqWVUtr6rLxtjvF6qqVdVZo9snVNX6qrpl9PHZ3a01eW+eOAAA+1ZVDSW5Msm7kqxKsqiqFrbW7thpvxlJfiPJd3Y6xIrW2ul7up4riwAAE8s5SZa31u5urY0kuSbJhbvY7xNJ/iDJhpeymFgEAJhYZiVZObC9anRsu6p6fZI5rbV/2MX8uVX1g6q6qareurvFvA0NAHAAqapLklwyMHRVa+2qFzB/UpLPJLl4Fy8/mOS41tpjVXVmkr+tqlNaa0/1jicWAQAOIKNhOFYcrk4yZ2B79ujYc2YkOTXJjVWVJK9IsrCqLmitLU6ycXSd71XViiQnJVncW8zb0AAAE8uiJPOqam5VDSe5KMnC515srT3ZWjuitXZCa+2EJDcnuaC1triqjhy9QSZV9cok85LcPdZiriwCAEwgrbXNVXVpkuuSDCW5urW2pKquSLK4tbZwjOlvS3JFVW1KsjXJR1tra8daTywCAEwwrbVrk1y709jlnX3PHXj+10n++oWs5W1oAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOiaPN4nAAAwEZ123EnjfQr7hSuLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXZPH+wT48XLkIYfnZ898e+a8/BXZsGljvrdiSW5Y8t201rpzDps2I7/1c7/yvPFb77szX/z2P+7L0wX2kUNnHpyz3jw3Rx49PSMjW7J86Zrc9r2VGeOPgiTJlOGhnPWmEzJ77uGpJKvvfzyLvnlvRjZu3r7PpEmVU86YlVeedGQOnjac9c+O5J67Hsnt31+drVt/tMChMw/OmW86IUe9YkY2b96a++9+LN//9n3ZvHnrPvqp4ceTWGSvOWjK1PzKO96bR55cmz//xpdy+PRDc/4Zb01V5Su33bzb+V/+wTdy36MPbt9et3H9vjxdYB8ZHh7KT//s/Dz5+LrceN2yzDjkoJz5xuNTlfzzopVjzn3ru07KIYcelJtvXJG05IyfOi7nLnh1/uffLdm+zxlvOC7z5h+df160MmsffTaHHzEtrzvnuAxPnZzF/3Rvkm3Red7Pzc/TT27IN75yV6YeNDmv/6njc/DLhnPTdcv25Y8P+0VVLUjyX5MMJfmT1trvd/b7hSR/leTs1tri0bGPJflIki1Jfr21dt1Ya4lF9ppzTnxtpgxNzhe+eW02bh7JiodXZuqU4bzz1DfkG0u/n42bR8ac/+jTj2fVYw/tp7MF9pV5pxydocmT8vXr7symTVvyUJ7MlOGhnHbm7NxxywPZtGnLLucdcfT0HDvnsPzPv7s9ax58Okmybt1Izv/51+YVsw7NQ6ufTJKcMO+I3HnHw1l667a/XD78wFN52bThnDDviO2xeNLoOXztyz/MppFt623csDnvOP/kHH7ktKx95Nl9/G8B9p2qGkpyZZJ3JVmVZFFVLWyt3bHTfjOS/EaS7wyMzU9yUZJTkhyb5CtVdVJrbdf/YcZnFtmLTjrm+Nz14P07ROFt99+Z4clTcsJRs8bxzID96dg5M/Pgyid2iMJ7lz+ayVOGctSxh4w5b/26ke2hmCSPrXkmTz+1Icced9j2sUmTansAPmdkZEuqavv2zJdvC8LB/R5c9URaa5l13MyX9PPBAeCcJMtba3e31kaSXJPkwl3s94kkf5Bkw8DYhUmuaa1tbK3dk2T56PG6XFlkrznikJm5e82qHcaeXPdMRjZvypGHzMyyB+4Zc/7Pn/OuHDw8Nc9uXJ9b77sz19/2rWze0v2LDnCAOnTmwXn4gSd3GFv3zEg2b9qSQw87OKvve7wz76A89cTzP37y1OPrc+hhB2/fXr50TebNPzoPrX4yjz/6bGYeMS0nzT86y27/0TsTQ0OTsnXLjh+QbFtbWtt2fjDBzUoy+JmOVUneMLhDVb0+yZzW2j9U1X/Yae7NO80d84rObmOxqk7Otgp97kCrkyxsrS3d3Vx+shw8PDXrRzY+b3z9yMYcPDy1O2/zli25+c5/zvKHtl2VnHvU7Lz15DNz+PRD8+ff/NK+PGVgHxgeHtrhhpTnbNy4OcNTh/rzpk7OyMbn/wVxZOPmTD/koO3bP/jO/RmaPCnvee+p28eW3f5Qbvvej/6y+vRTGzL3xCNSkypt9KaXw4+cnkmTKsNTXSfhwFZVlyS5ZGDoqtbaVS9g/qQkn0ly8d44nzH/i6mq307ygWy7vPnd0eHZSf6iqq7pfZgSXohnNqzLl75/0/bte9aszjMb1uWCs96RVxx2RB564tFxPDvgQDP/9GMzd96R+e437skTa5/NzJdPy+vOnpONGzbn1sXbLrYsX/pwTn7tMTn7zSfk1sWrMvWgyTnnrXO33S29mzuyYbyNhuFYcbg6yZyB7dmjY8+ZkeTUJDeOfjzjFUkWVtUFezD3eXb316uPJDmltbZpcLCqPpNkSRKxyHbrRzbmoCnDzxvvXXEcy+0rl+eCs96RY2ceJRZhghkZ2ZIpw8//38vUzpXD7fM2bs7Ug6Y8b3zbFcdtVyqnHjQ5rzt7ThZ9854sX7omSbLmwaezdcvWnP2WuVl2+4PZuGFznnpiQ75z04qc+aYTctIpr8jWrS3Llz6ctGT9+rFvtoMJYFGSeVU1N9tC76IkH3zuxdbak0mOeG67qm5M8luttcVVtT7JF0Zb7tgk8/KjC4K7tLtY3Dp6oPt2Gj9m9LVdGrx8ev6/eX9e/9Nv2s0y/Dh49KnHc+QhO35w/NCXTc/w5Cl55Kldf0apa/uXsbkEABPNkzt9xjBJXjZtOJOnDOXJXXwm8UfzNmTea55/A8whhx2clfeuTZJMP+SgDA1NyuOP7ng389rH1mXS0KRMnzE1GzdsC8sVyx7JPcsfzSGHHpwN6zdl44ZNed/FZ2f5D9e81B8RxlVrbXNVXZrkumz76pyrW2tLquqKJItbawvHmLukqr6Y5I4km5P82lh3Qie7j8X/NclXq+qu/OiDlMclOTHJpWOcyPbLp797zR/5v/1PiDsfvC9vOfn1GZ48JSObt12MPnXOvIxs3pR714x5hft5TplzYpJk9Vp/qMNE88DKxzP/dbMyecqkbN607brC8Se+PJs3bcmaB54ac95pZ83Oka+YkUce2nZH9OFHTsuMQw/KA/c/kSR59ult71IcfsS0PDbw9TeHHzEtSfLM0zu+i7F1S8sTa9clSV550pFJJfeteGwv/aQwflpr1ya5dqexyzv7nrvT9ieTfHJP1xozFltr/1hVJ2XbLdWDN7gs2l2F8pPnu8tvyxtPel0++JafyTeWfi8zpx+Sd576hnxr2Q92+Dqdf/czv5x7H1mdv/nuV5Mk7zz1DRmePCX3P/pgNm4ayQlHHpu3nHxmlqxcnoef9Ic6TDR3LXk4J596TN7+nldnyQ8eyPRDpua0s+Zk6a0P7vB1Ohd+4Iw8/MBTufmmFUmSRx9+Jg+sfCJveueJ+f6370trLa//qeOz5sGntn/H4ob1m3L/PWtzxk8dn0mTJ+WJx9Zl5hHTctqZs3Pfike3X1WcMmUop75+VtY8+FS2bm05etahmX/aMbn563fv8uYboG+3t4S11rZmx1usYZc2bNqYq7/2N/m5M9+eD73157Jh08Z8685bcsPt39lhv0mTJu3wfWiPPLU2bzn59Tnrladk8tDkPLnu6Xzzh9/LjXcs3t8/ArAXjIxsyVe+dEfOfsvcnHv+ydm0cXN+eOuD228+eU5N2vYY9I3r78xZbzohbzz3VUklq+97Iov/acev3fr2Dcvz2jNn5+RTj9n+6/7uWvrwDndDb20tM4+YlhNfs+3LuZ9cuy5fv/7OrLr3BX4kBkiN9Tt79wZvQwN76uQnzh7vUwAmiA999I21+732rS9+6x/3SeP84psWjPvPNshvcAEAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCArsnjfQIAABPR6447abxPYb9wZREAgC6xCABAl1gEAKBLLAIA0CUWAQDoEosAAHSJRQAAusQiAABdYhEAgC6xCAAwwVTVgqpaVlXLq+qyXbz+0aq6rapuqapvVtX80fETqmr96PgtVfXZ3a3l1/0BAEwgVTWU5Mok70qyKsmiqlrYWrtjYLcvtNY+O7r/BUk+k2TB6GsrWmun7+l6riwCAEws5yRZ3lq7u7U2kuSaJBcO7tBae2pgc1qS9mIXE4sAABPLrCQrB7ZXjY7toKp+rapWJPlUkl8feGluVf2gqm6qqrfubjGxCABwAKmqS6pq8cDjkhdznNbala21VyX57SS/Ozr8YJLjWmtnJPnNJF+oqkPGOo7PLAIAHEBaa1cluWqMXVYnmTOwPXt0rOeaJP/P6LE3Jtk4+vx7o1ceT0qyuDfZlUUAgIllUZJ5VTW3qoaTXJRk4eAOVTVvYPNnktw1On7k6A0yqapXJpmX5O6xFnNlEQBgAmmtba6qS5Ncl2QoydWttSVVdUWSxa21hUkurarzkmxK8niSD49Of1uSK6pqU5KtST7aWls71npiEQBggmmtXZvk2p3GLh94/hudeX+d5K9fyFrehgYAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAIAJpqoWVNWyqlpeVZft4vWPVtVtVXVLVX2zquYPvPax0XnLquo9u1tLLAIATCBVNZTkyiTnJ5mf5AODMTjqC62117bWTk/yqSSfGZ07P8lFSU5JsiDJH48er0ssAgBMLOckWd5au7u1NpLkmiQXDu7QWntqYHNakjb6/MIk17TWNrbW7kmyfPR4XWIRAOAAUlWXVNXigcclO+0yK8nKge1Vo2M7H+fXqmpFtl1Z/PUXMnfQ5Bf6AwAAsO+01q5KctVeOM6VSa6sqg8m+d0kH34xx3FlEQBgYlmdZM7A9uzRsZ5rkrz3Rc4ViwAAE8yiJPOqam5VDWfbDSsLB3eoqnkDmz+T5K7R5wuTXFRVU6tqbpJ5Sb471mLehgYAmEBaa5ur6tIk1yUZSnJ1a21JVV2RZHFrbWGSS6vqvCSbkjye0begR/f7YpI7kmxO8muttS1jrScWAQAmmNbatUmu3Wns8oHnvzHG3E8m+eSerrXPY/HkJ87e10sAPybevuBV430KAOzElUUAgBfhZZunj/cp7BducAEAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBACaYqlpQVcuqanlVXbaL13+zqu6oqlur6qtVdfzAa1uq6pbRx8LdrTV5b588AAD7TlUNJbkyybuSrEqyqKoWttbuGNjtB0nOaq2tq6p/m+RTSd4/+tr61trpe7qeK4sAABPLOUmWt9bubq2NJLkmyYWDO7TWvtZaWze6eXOS2S92MbEIAHAAqapLqmrxwOOSnXaZlWTlwPaq0bGejyT58sD2QaPHvbmq3ru78/E2NADAAaS1dlWSq/bGsarqQ0nOSvL2geHjW2urq+qVSW6oqttaayt6x3BlEQBgYlmdZM7A9uzRsR1U1XlJfifJBa21jc+Nt9ZWj/7z7iQ3JjljrMXEIgDAxLIoybyqmltVw0kuSrLDXc1VdUaSz2VbKK4ZGJ9ZVVNHnx+R5M1JBm+MeR5vQwMATCCttc1VdWmS65IMJbm6tbakqq5Isri1tjDJp5NMT/KXVZUk97fWLkjymiSfq6qt2XbR8Pd3uov6ecQiAMAE01q7Nsm1O41dPvD8vM68byV57QtZy9vQAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAICuyeN9AgAAE9G9y9fuk+POOeGofXLcF8uVRQAAusQiAABdYhEAgC6xCABAl1gEAKBLLAIA0CUWAQDoEosAAHSJRQAAusQiAABdYhEAgC6xCABAl1gEAKBLLAIA0CUWAQDoEosAAHSJRQAAusQiAABdYhEAgC6xCABAl1gEAKBLLAIA0CUWAQDoEosAABNMVS2oqmVVtbyqLtvF679ZVXdU1a1V9dWqOn7gtQ9X1V2jjw/vbi2xCAAwgVTVUJIrk5yfZH6SD1TV/J12+0GSs1prpyX5qySfGp17eJKPJ3lDknOSfLyqZo61nlgEAJhYzkmyvLV2d2ttJMk1SS4c3KG19rXW2rrRzZuTzB59/p4k17fW1rbWHk9yfZIFYy0mFgEADiBVdUlVLR54XLLTLrOSrBzYXjU61vORJF9+kXMzec9OGwCA/aG1dlWSq/bGsarqQ0nOSvL2F3sMsciLdujMg3PWm+fmyKOnZ2RkS5YvXZPbvrcyrfXnTJpUOf2c43LE0dNz+JHTM3nypPzZZ7895jqzT5iZcxecnMfWPJMv/4/b9vJPAewP9913T/7vP/7D3LF0SaZPm57zF/xs/tWHfiVDQ0PdOT9ctjR///d/k9tuvzWPrX00Rx55VN75jnflol/8YIaHp27f75d++X15+OGHdnmM/+8Lf5OXv/yIvf7zwDhbnWTOwPbs0bEdVNV5SX4nydtbaxsH5p6709wbx1pMLPKiDA8P5ad/dn6efHxdbrxuWWYcclDOfOPxqUr+edHK7ryhyZPyqtcclcfWPJNHHno6x8w+dMx1Jg1VznzTCVm/bmRv/wjAfvL000/nf7vs3+W4407IFR//L3ngwdX53FVXZmtr+dcX/y/deTfddEMeePCBvP8XP5hZs+bknntW5PN/+ie5++4V+b3L/9P2/X7v8k9m06ZNO8z9zB9+KkOTJglFflwtSjKvquZmW/xdlOSDgztU1RlJPpdkQWttzcBL1yX5zwM3tbw7ycfGWkws8qLMO+XoDE2elK9fd2c2bdqSh/JkpgwP5bQzZ+eOWx7Ipk1bdjlv08iW/OXnFyVJTjrlFbuNxVNed2zWPzuSp5/akMNmvmyv/xzAvvf3//C32TiyMb93+Sczbdq0nJmzs27ds/nvf/b5vP99H8y0adN2Oe+i9/9SDj30sO3bp7/ujEwZHs4f/tdP5+GHH8rRR78iSTLvxJN2mLd27WO5//77xgxRmMhaa5ur6tJsC7+hJFe31pZU1RVJFrfWFib5dJLpSf6yqpLk/tbaBa21tVX1iWwLziS5orW2dqz13ODCi3LsnJl5cOUTO0ThvcsfzeQpQznq2EP2yhovmz6c+afPyuJ/unevHA8YH4sWfSdnnXnODlF47rnnZePGjbn1tlu68wZD8TknvmpekuSxxx7tzrvp619La1vzjnN/+iWcNRzYWmvXttZOaq29qrX2ydGxy0dDMa2181prR7fWTh99XDAw9+rW2omjj8/vbi2xyIty6MyD89QT63cYW/fMSDZv2pJDDzt4r6xx5htPyH0rHsvaR5/dK8cDxsfKlfdlzpzjdxg7+qijc9DUg3L/yvte0LGWLl2SSZMm5Zhj+zdvfu3Gr2b+a07ZfuUReGnEIi/K8PBQRjZuft74xo2bMzy1/4H1PXX0sYfkmNmH5pbv3v+SjwWMr6efeTrTp01/3vj0GTPyzNNP7/Fx1q59LH/+hT/NeT/97sw8bNffIfzwww9l6Q+X5FxXFWGvedGxWFW/sjdPBJ5TlZz9lrm5/Qers2H9pt1PAH7sbdq0KZ/45Mdz0MEH59/+6q939/vajV9N1aSc+7Z37sezgx9vL+XK4n/svTD4ZZI3fONvX8ISHKhGRrZkyvDz74+aOnVyRjbu+uaWPXXia47OlOGhrPjhmkwZHsqU4aFMmjQpNakyZXgoNale0vGB/WvG9Bl5dt3zP07yzNNPZ/qMGbud31rLH3z6P+Xe++7Jf/7EpzNjjDlfu+mrOf11Z2TmzMNf0jkDPzLm3dBVdWvvpSRH9+YNfpnkn33222N86x4T1ZOPr3/eZxNfNm04k6cM5cmdPsv4Qh1y2MGZNn1q3nfx2c977f3/+pz801fvyj139T/cDhxY5sw5Pit3+mzimjUPZ8PGDTlup88y7soff/aP8q1vfzN/8F/+zxx3XH//lSvvz4oVd+Xf/+ZlL/mcgR/Z3VfnHJ1tv0Pw8Z3GK8m39skZMSE8sPLxzH/drEyeMimbN21Nkhx/4suzedOWrHngqZd07GW3P5RV9+54F/8pp8/K9EOm5jtfvztPPv7SYhTYv84++w35y7/8i6xbty4ve9m2r8C68aYbMnXq1Jz22tPHnPuFa/7f/N3C/5Hf/d//Y1576mlj7nvDjV/JlClT8tY3v22vnTuw+1j8UpLprbXnfbdBVd24T86ICeGuJQ/n5FOPydvf8+os+cEDmX7I1Jx21pwsvfXBHb5O58IPnJGHH3gqN9+0YvvYsXMOy+Qpk3L4Edv+p3HcK7e9XfTYmmfy7DMjeeapDXnmqQ07rPfKVx+ZqQdNzsMvMUSB/e/nfua9+du/+6v83hW/k/f/4i/lwYceyH//s8/nF37+/Tt8nc4vX3xRTjvt9PzW6JXBr95wfa7+/FV5z7vOzxFHHJk7li7Zvu+xxxybw3a6yeWmm27I2We9IdOn7/6tbWDPjRmLrbWPjPHaB3uv8eNvZGRLvvKlO3L2W+bm3PNPzqaNm/PDWx/MrYt3/O0tNWnbY9A5b5ub6TMO2r79tne/Oknyra8tz93LHtnn5w7sXzNmzMinf/8P839d+Yf5Pz7+25k+fXp+4ed/Mb/8oR3vk9yydUu2bv3RXza/9/3vJkmuu/7Lue76L++w73/49x/Le979L7ZvL19xV+5feV/+1Ycu3nc/CPyEqjbWL/LdC3xmEdhTb1/wqvE+BWCCmHPCUeN+t+M3vvLDfdI4bz3v5HH/2Qb5nkUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6BKLAAB0iUUAALrEIgAAXWIRAIAusQgAQJdYBACgSywCANAlFgEA6Jo83icAADAR3bf88X1y3Leet08O+3w+ECIAAATwSURBVKK5sggAQJdYBACgSywCAEwwVbWgqpZV1fKqumwXr7+tqr5fVZur6l/u9NqWqrpl9LFwd2v5zCIAwARSVUNJrkzyriSrkiyqqoWttTsGdrs/ycVJfmsXh1jfWjt9T9cTiwAAE8s5SZa31u5Okqq6JsmFSbbHYmvt3tHXtr7UxbwNDQAwscxKsnJge9Xo2J46qKoWV9XNVfXe3e3syiIAwAGkqi5JcsnA0FWttav24hLHt9ZWV9Urk9xQVbe11lb0dhaLAAAHkNEwHCsOVyeZM7A9e3RsT4+/evSfd1fVjUnOSNKNRW9DAwBMLIuSzKuquVU1nOSiJLu9qzlJqmpmVU0dfX5Ekjdn4LOOuyIWAQAmkNba5iSXJrkuydIkX2ytLamqK6rqgiSpqrOralWS9yX5XFUtGZ3+miSLq+qfk3wtye/vdBf183gbGgBggmmtXZvk2p3GLh94vijb3p7eed63krz2hazlyiIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoEssAgBMMFW1oKqWVdXyqrpsF6+/raq+X1Wbq+pf7vTah6vqrtHHh3e3llgEAJhAqmooyZVJzk8yP8kHqmr+Trvdn+TiJF/Yae7hST6e5A1Jzkny8aqaOdZ6YhEAYGI5J8ny1trdrbWRJNckuXBwh9bava21W5Ns3Wnue5Jc31pb21p7PMn1SRaMtZhYBACYWGYlWTmwvWp0bJ/MFYsAAAeQqrqkqhYPPC4Zz/OZPJ6LAwCwo9baVUmuGmOX1UnmDGzPHh3bE6uTnLvT3BvHmuDKIgDAxLIoybyqmltVw0kuSrJwD+del+TdVTVz9MaWd4+OdYlFAIAJpLW2Ocml2RZ5S5N8sbW2pKquqKoLkqSqzq6qVUnel+RzVbVkdO7aJJ/ItuBclOSK0bEub0MDAEwwrbVrk1y709jlA88XZdtbzLuae3WSq/d0LVcWAQDoEosAAHSJRQAAusQiAABdYhEAgC6xCABAl1gEAKCrWmvjfQ78BKqqS0Z/nRHAmPx5AePLlUXGy7j+UnRgQvHnBYwjsQgAQJdYBACgSywyXnz+CNhT/ryAceQGFwAAulxZBACgSyyy31XVgqpaVlXLq+qy8T4f4MBUVVdX1Zqqun28zwV+kolF9quqGkpyZZLzk8xP8oGqmj++ZwUcoP5bkgXjfRLwk04ssr+dk2R5a+3u1tpIkmuSXDjO5wQcgFprX0+ydrzPA37SiUX2t1lJVg5srxodAwAOQGIRAIAuscj+tjrJnIHt2aNjAMABSCyyvy1KMq+q5lbVcJKLkiwc53MCADrEIvtVa21zkkuTXJdkaZIvttaWjO9ZAQeiqvqLJN9O8uqqWlVVHxnvc4KfRH6DCwAAXa4sAgDQJRYBAOgSiwAAdIlFAAC6xCIAAF1iEQCALrEIAECXWAQAoOv/Bzz6tiQ7ZgmlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s_ThV6bj6cZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}